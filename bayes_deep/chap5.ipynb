{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ベイズニューラルネットワークモデルの近似推論法  \n",
    "バッチ学習によるニューラルネットワークの基本的な学習手法  \n",
    "入力データ$X = \\{x_1, ..., x_N\\}$  \n",
    "観測データ$Y=\\{y_1,...,y_N\\}$  \n",
    "パラメータ$W$\n",
    "$$\n",
    "p(y, W|X) = p(W) \\prod_{n=1}^N p(y_n |x_n, W) \\tag{1}\n",
    "$$\n",
    "とおく  \n",
    "$x_n\\in \\mathbb{R}^{H_0}$から$y_n \\in \\mathbb{R}^D$を予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(y_n|x_n, W) = N(y_n|f(x_n;W), \\sigma^2_yI) \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x_n;W)$がニューラルネットワーク  \n",
    "ここでは分散$\\sigma^2_y$は固定のノイズ項\n",
    "$$\n",
    "f(x_n;W) = \\sum_{h_1=1}^{H_1} w_{d,h1}^{(2)}\\phi \\left( \\sum_{h_0=1}^{H_0} w_{h_1, h_0}^{(1)} x_{n,h_0} \\right) \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データが与えられた後のパラメータの事後分布をべいず推論で計算するのでパラメータに事前分布を設定する必要がある  \n",
    "ここでは各重みパラメータを$w\\in W$とし，それぞれに独立なガウス分布を与える  \n",
    "$$\n",
    "p(w) = N(w|0,\\sigma_w^2) \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 ラプラス近似による学習  \n",
    "式(1)のニューラルネットワークモデルに対するラプラス近似による学習と予測を導出する  \n",
    "簡単のためD=1とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. モデルの事後分布のMAP推定値を最適化により求める　　\n",
    "$$\n",
    "p(W|Y,X) \\propto p(W)p(Y|X,W) \\tag{5}\\\\\n",
    "$$\n",
    "局所最適解$W_{MAP}$の更新は対数事後分布の勾配を利用して\n",
    "$$\n",
    "W_{new} = W_{old} + \\alpha \\nabla _w \\log P(W|Y, W)|_{W=W_{old}} \\tag{6}\n",
    "$$\n",
    "2. 周辺をガウス分布によって求める  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータ$w\\in W$の偏微分を計算すると   \n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} \\log p(W|Y,X) = - \\left\\{ \\frac{1}{\\sigma_y^2}\\frac{\\partial}{\\partial w} E(W) + \\frac{1}{\\sigma_w^2}\\frac{\\partial}{\\partial w} \\Omega_{L2} \\right\\} \\tag{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Omega_{L2}$は正規化項で，容易に微分できる  \n",
    "$E(W)$はニューラルネットワークの誤差関数  \n",
    "\n",
    "ラプラス近似で計算される近似が近似事後分布を\n",
    "$$\n",
    "q(W) = N(W|W_{MAP}, \\{\\Lambda (W_{MAP})\\}^{-1}) \\tag{9}\n",
    "$$\n",
    "とおく  \n",
    "精度行列$\\Lambda$は\n",
    "\\begin{eqnarray}\n",
    "    \\Lambda = -\\nabla^2_W \\log p(W|Y,X) \\\\\n",
    "    = \\frac{1}{\\sigma_w^2} I + \\frac{1}{\\sigma_y^2}H \\tag{10}\n",
    "\\end{eqnarray}\n",
    "$H$はヘッセ行列で厳密計算あるいは近似計算によって求められる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2.2. 予測分布の近似  \n",
    "$$\n",
    "p(y_*|x_*, Y, X) \\approx  \\int p(y_* | x_*, W) q(W)dW \\tag{11}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータWはq(W)としてガウス分布で近似しているが$p(y_*|x_*, W)$の中にニューラルネットワークが含まれているので解析的に計算できない　　\n",
    "→ニューラルネットワークの線形近似を行う  \n",
    "パラメータの事後分布の密度がMAP推定値の周辺に集中していて，その範囲においてニューラルネットワークの間数値$f(x_*, W)$がWの線形関数でよく近似できるという仮定をおく  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "f(x_* ; W) \\approx f(x_* ; W_{MAP}) + g^T(W-W_{MAP}) \\tag{12} \\\\\n",
    "g = \\nabla wf(x_*;W)|_{W=W_{MAP}} \\tag{13}\n",
    "\\end{eqnarray}\n",
    "テイラー展開でWの関数$f(x_*;W)$を$W_{MAP}$周りで一次近似したもの  \n",
    "gは関数の勾配を$W_{MAP}$で評価したもの  \n",
    "この近似を使えばニューラルネットワークの非線形性がなくなるので解析的に計算できるようになる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "    p(y_*|x_*, Y, X ) \\approx \\int p(y_* | x_*, W)q(W)d(W) \\\\\n",
    "    \\approx \\int N(y_*|f(x_* ; W_{MAP} ) + g^T(W - W_{MAP} ), \\sigma^2_y)N(W|W_{MAP}, \\{\\Lambda (W_{MAP})\\}^{-1})dW\\\\\n",
    "    = N(y_* | f(x_*; W_{MAP}), \\sigma^2(x_*)) \\tag{14} \\\\\n",
    "    ただし \\sigma^2(x_*) = \\sigma^2_y + g^T\\{\\Lambda (W_{MAP})\\}^{-1}g\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 ハミルトニアンモンテカルロ法による学習  \n",
    "ハミルトニアンモンテカルロ法を利用したベイズミューラルネットワークの事後分布からのサンプリング  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハミルトニアンモンテカルロ法は対数事後分布がサンプリングしたい変数に関して微分可能であれば適用できる  \n",
    "離散変数をパラメータとしてもたないニューラルネットワークではハミルトニアンモンテカルロ法に必要な微分情報の計算には誤差逆伝播ほうが使える  \n",
    "計算時間さえ十分に確保していれば理論的には真の事後分布からのサンプルが得られる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式(5)の正規化されていない事後分布を利用すると対応するポテンシャルエネルギーは\n",
    "$$\n",
    "U(W) = - \\{\\log p(Y|X,W) + \\log p(W)\\} \\tag{16}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リープフロッグ法を使うためにはポテンシャルエネルギーの微分が必要  \n",
    "→正則化項を付け加えたコスト関数の微分と等価なので誤差逆伝播法による勾配計算が利用できる  \n",
    "ハミルトニアンモンテカルロ法では予測の不確実性がサンプリングに基づく手法で得られる複数の関数のサンプリングから表現される  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3.2 ハイパーパラメータの推論\n",
    "重みパラメータWの事前分布を支配する$\\sigma^2_w$や観測モデルのノイズパラメータ$\\sigma^2_y$などのハイパーパラメータに対して事前分布を設定する  \n",
    "パラメータWは分散$\\sigma^2_w$を持つガウス分布に従って決定される\n",
    "$$\n",
    "p(\\gamma_w) = Gam(\\gamma_w|a_w,b_w) \\tag{17} \\\\\n",
    "ただし\\gamma_w = \\sigma^{-2}_w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "観測ノイズも式(17)同様にガンマ分布を設定する  \n",
    "これらの精度パラメータの事前分布を導入した場合のモデルは  \n",
    "$$\n",
    "p(Y,W,\\gamma_w, \\gamma_y | X) = p(\\gamma_w)p(\\gamma_y)p(W|\\gamma_w) \\prod_{n=1}^N p(y_n|x_n, W, \\gamma_y) \\tag{19}\n",
    "$$\n",
    "従って事後分布全体は\n",
    "$$\n",
    "p(W,\\gamma_w, \\gamma_y|Y,X) \\tag{20}\n",
    "$$となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求めたい確率変数($W, \\gamma_w, \\gamma_y$)を条件付き確立を用いて別々にサンプリングする  \n",
    "→他の２変数を既知として求めたいパラメータのみを確率変数として扱う  \n",
    "$$\n",
    "p(W|T,X, \\gamma_w, \\gamma_y) \\tag{21}\n",
    "$$\n",
    "これはパラメータの事後分布そのままなのでハミルトニアンモンテカルロ法を実行することでWのサンプルを得られる  \n",
    "$$\n",
    "p(\\gamma_w|Y,X,W,\\gamma_y) \\propto p(W|\\gamma_w)p(\\gamma_w) \\tag{22}\n",
    "$$\n",
    "$p(W|\\gamma_w)$はガウス分布，$\\gamma_w$の事前分布はガンマ分布なので22式もガンマ分布として解析的に求められる  \n",
    "\\begin{eqnarray}\n",
    "\\gamma_w ~ Gam(\\hat{a}_w, \\hat{b}_w) \\tag{23}\\\\\n",
    "\\hat{a}_w = a_w + \\frac{K_w}{2} \\tag{24}\\\\\n",
    "\\hat{b}_w = b_w + \\frac{1}{2} \\sum_{w\\in W} w^2 \\tag{25}\\\\\n",
    "ただし，K_wは重みパラメータWの総数\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(\\gamma_y|Y,X,W,\\gamma_w) \\propto p(\\gamma_y) \\prod_{n=1}^N p(y_n|x_n,W, \\gamma_y) \\tag{26}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "と計算できる  \n",
    "観測モデル$p(Y|W,X,\\gamma_y)$がガウス分布，$\\gamma_y$の事前分布にはガンマ分布を用いているので解析的に分布の計算ができる "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 近似ベイズ推論の効率化  \n",
    "ベイズニューラルネットワークはパラメータの周辺化に伴う計算量が膨大で現実的でない  \n",
    "膨大なデータに対しても近似的なベイズ推論ができる手法を考える  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 確率的勾配ランジュバン動力学法による学習  \n",
    "問題点\n",
    "1. 確率的勾配降下法は学習効率向上に大きく貢献しているがパラメータの不確実性を取り扱えない手法では上手くいかない  \n",
    "2. ハミルトニアンモンテカルロ法などの勾配を利用したサンプリング方法大規模なデータに対して計算効率が良くない  \n",
    "\n",
    "そこで  \n",
    "学習効率を上げる確率的勾配降下法と不確実性の推定が可能なランジュバン動力学法を組み合わせた**確率的勾配ランジュバン動力学法**を用いる  \n",
    "確率的勾配降下法とマルコフ連鎖モンテカルロ法を組み合わせた手法は確率的マルコフ連鎖モンテカルロ法と呼ばれる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率的勾配降下法を用いてニューラルネットワークの正則化項付きのコスト関数を更新は  \n",
    "パラメータの更新を$W_{new}=W_{old}+\\Delta W$と書くと，\n",
    "$$\n",
    "\\Delta W = \\frac{\\alpha_t}{2} \\left\\{ \\frac{N}{M} \\sum_{n\\in S} \\nabla_W \\log p(y_n|x_n, W) + \\nabla_w \\log p(W) \\right\\} \\tag{27}\n",
    "$$\n",
    "ここで$\\alpha_t$は学習率  \n",
    "学習率は\n",
    "$$\n",
    "\\sum_{i=1}^{\\infty}\\alpha_i = \\infty, \\sum_{i=1}^{\\infty} \\alpha_i^2 \\lt \\infty \\tag{A1}\n",
    "$$\n",
    "を満たすようなものにするとミニバッチによる更新が停留点に収束することが知られているらしい  \n",
    "- 最もシンプルな式A1を満たすスケジューリング方法は$\\alpha_i = \\frac{\\alpha}{i}, (\\alpha\\gt0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランジュバン動力学法のサンプル候補を得るために必要なステップは\n",
    "\\begin{eqnarray}\n",
    "\\Delta W = \\frac{\\alpha_t}{2} \\left\\{ \\sum_{n=1}^N \\nabla_W \\log p(y_n|x_n, W) + \\nabla_W \\log p(W) \\right\\} + \\sqrt{\\alpha_t}p \\tag{28}\\\\\n",
    "ポテンシャルエネルギー:U = -\\log p(W|Y,X)\\\\\n",
    "ステップサイズ:\\epsilon = \\sqrt{\\alpha_t}\\\\\n",
    "運動量ベクトル:p~N(0,I)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ランジュバン動力学法では離散化による誤差を修正するためにメトロポリス・ヘイスティングス法による候補点の受容の可否を決める必要がある\"と書いてあるが離散化がどこを指しているのかわからなかった  \n",
    "学習率を小さくすれば受容率を限りなく１に近づける事ができる  \n",
    "式27,28を組み合わせればランジュバン動力学法のミニバッチ版を考える事ができる  \n",
    "$$\n",
    "\\Delta W = \\frac{\\alpha_t}{2} \\left\\{ \\frac{N}{M} \\sum_{n\\in S} \\nabla_W \\log p(y_n|x_n, W) + \\nabla_W \\log p(W) \\right\\} + \\sqrt{\\alpha_t}p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでも学習率が式A1を満たすようにする事でサンプルの繰り返し回数が$t\\rightarrow\\infty$となるにつれてメトロポリス・ヘイスティングス法の受容率が漸近的に1になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2. 確率的変分推論法による学習  \n",
    "変分推論法と確率的勾配効果法によるミニバッチを使った学習方法である**確率的変分推論法**について  \n",
    "変分パラメータの集合を$\\xi$としてニューラルネットワークのパラメータWの事後分布を分布$q(W;\\xi)$で独立なガウス分布で近似する  \n",
    "$$\n",
    "q(W;\\xi) = \\prod_{i,j,l} N(w_{i,j}^{(i)}|\\mu_{i,j}^{(l)},\\sigma_{i,j}^{(l)^2})\n",
    "$$\n",
    "この時のELBOは  \n",
    "$$\n",
    "L(\\xi) = \\sum_{n=1}^N \\int q(W;\\xi) \\log p(y_n|f(x_n;W))dW - D_{KL}[q(W;\\xi)||p(W)] \\tag{29}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELBOを勾配降下法を利用して変分パラメータ$\\xi$に関して最大化する場合，ステップごとの勾配評価のために学習データセットを全て読み込んで計算する必要がある  \n",
    "→コストを考えるとできるだけ避けたい  \n",
    "*ミニバッチを使った最適化をしたい*  \n",
    "**データセットから部分的なELBOを評価する**\n",
    "$$\n",
    "L_S(\\xi) = \\frac{N}{M} \\sum_{n\\in S} \\int q(W;\\xi) \\log p(y_n|f(x_n;W))dW -D_{KL}[q(W;\\xi)||p(W)] \\tag{30}\n",
    "$$\n",
    "データセットのサンプリングによって計算された$L_s$は全データを使った場合のLに対する不偏推定量になる\n",
    "$$\n",
    "\\mathbb{E}_s[L_s(\\xi)] = L(\\xi)\n",
    "$$\n",
    "このようにミニバッチのELBOを最大化する事で大規模データに対しても効率よくパラメータの事後分布を近似できる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 勾配のモンテカルロ近似  \n",
    "式30の変分パラメータによる勾配の計算\n",
    "- KLダイバージェンスの項はどちらもガウス分布なので解析的に計算できる  \n",
    "- 対数尤度の項は解析的に積分できない\n",
    "    - 厳密計算を行う代わりにモンテカルロ法を使って積分を近似し，勾配の推定を得る\n",
    "\n",
    "近似した勾配$I(\\xi)$を評価する  \n",
    "$$\n",
    "I(\\xi) = \\nabla_{\\xi} \\int f(w)q(w;\\xi)dw \\tag{31}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$I(\\xi)$を計算する方法**\n",
    "**スコア関数推定**\n",
    "$$\n",
    "\\nabla_{\\xi}q(w;\\xi) = q(w;\\xi)\\nabla_{\\xi} \\log q(w;\\xi) \\tag{32}\n",
    "$$\n",
    "を使って式31を評価する  \n",
    "\\begin{eqnarray}\n",
    "\\nabla_{\\xi} \\int f(w) q(w;\\xi)dw = \\int f(w)\\nabla_{\\xi} q(w;\\xi)dw \\\\\n",
    "= \\int f(w)q(w;\\xi)\\nabla_{\\xi} \\log q(w;\\xi)dw  \\tag{33}\n",
    "\\end{eqnarray}\n",
    "つまり\n",
    "$$\n",
    "\\mathbb{E}_{q(w;\\xi)}[f(w)\\nabla_{\\xi} \\log q(w;\\xi)] = I(\\xi) \\tag{33}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なので分布$q(w;\\xi)$からwを複数サンプリングしてから微分を評価する事で$I(\\xi)$の不偏推定量が得られる  \n",
    "スコア関数推定は汎用性が高いものの高い分散を生じさせてしまうため効率的にELBOの最大化を行うためには制御変量法(分散を減少させる手法)と合わせて使う必要がある  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3.2 再パラメータ化勾配  \n",
    "wを変分パラメータ$\\xi$に依存した分布$q(w;\\xi)$から直接サンプリングする代わりに\n",
    "1. 変分パラメータのない分布から$\\epsilon$をサンプリングする\n",
    "2. $\\epsilon$を変換$w=g(\\xi;\\epsilon)$によりwを得る\n",
    "\n",
    "つまり\n",
    "$$\n",
    "\\mathbb{E}_{q(\\epsilon)}[f'(g(\\xi;\\epsilon))\\nabla_{\\xi} g(\\xi;\\epsilon)] = I(\\xi) \\tag{34}\n",
    "$$\n",
    "として勾配の不偏推定量を得る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
